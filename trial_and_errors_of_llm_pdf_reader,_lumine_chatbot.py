# -*- coding: utf-8 -*-
"""Trial and errors of LLM PDF reader, Lumine chatbot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w7vNpWvN7Rjmj_cbMjdHPhV2hJTOETcp
"""

!pip install langchain
!pip install langchain-openai
!pip install --upgrade langchain
!pip install langchain-community
!pip install faiss-gpu
!pip install pymupdf langchain

!pip install pymupdf langchain-openai langchain-core langchain-community

!pip install langchain-core
!pip install langchain-agents
!pip install pillow
!pip install pytesseract

import os
os.environ['OPENAI_API_KEY'] ="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"

import os
os.environ['TAVILY_API_KEY'] ="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"

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter
import re
import pytesseract
from PIL import Image
import concurrent.futures

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history, pdf_text_chunks):
    all_food_items = set()  # Use a set to avoid duplicates
    for chunk, store_name in pdf_text_chunks:
        food_items = extract_food_items([(chunk, store_name)])
        all_food_items.update(food_items)  # Add items to the set

    # Convert the set back to a list and filter out generic terms
    filtered_food_items = [(item, store) for item, store in all_food_items if item.lower() not in ['product', 'item', 'artikel']]

    # Create a numbered list
    response_text = "\n".join(f"{idx + 1}. {item}, {store}" for idx, (item, store) in enumerate(filtered_food_items))

    chat_history.append(HumanMessage(content=user_input))
    chat_history.append(AIMessage(content=response_text))

    return response_text

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def extract_text_from_multiple_pdfs(pdf_paths):
    combined_text = []
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_pdf = {executor.submit(extract_text_from_pdf, pdf_path): pdf_path for pdf_path in pdf_paths}
        for future in concurrent.futures.as_completed(future_to_pdf):
            pdf_path = future_to_pdf[future]
            try:
                data = future.result()
                store_name = pdf_path.split('/')[-1]  # Extract store name from the file path
                combined_text.append((data, store_name))
            except Exception as exc:
                print(f"{pdf_path} generated an exception: {exc}")
    return combined_text

def split_text(raw_text, store_name):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return [(chunk, store_name) for chunk in text_splitter.split_text(raw_text)]

def extract_food_items(text_chunks):
    food_items = []
    # Define a more specific pattern to avoid generic terms like 'product' and 'item'
    pattern = re.compile(r"\b(?:voedsel|drank|appel|krieltjes|asperges|lente-ui|rabarber|haakse slijper|volkorenbollen|koekrepen|choco muesli|kaas|eieren|shoarma|vegan shoarma|kaasmix|smeerkaaspuntjes|pancakes|wraps|burrata|koffiebonen|koffiedrank|gehakt|steaks|forelfilets|makreelfilet|kipfiletstukjes|wokgarnalen|zalmfilets|hamburgers|chipolataworstjes|garnalenspies|partysauzen|tortillachips|pommes frites|notenmix|batterijen|handzeep|chicken wings|rucola|perziken|nectarines|watermeloen|kipkerrie|tomaten|roerbakgroenten|pepersteaks|kabeljauwburgers|kiploempia's|muffins|yoghurt|currysnack|rendang|loaded fries|falafel|pizza|bladerdeeghapjes|stoofvlees|gehaktballen|scampi fritti|knoflookboter|knoflookbrood|kimchi|atjar|bakmix|ijs|breekbrood|borrelbroodjes|karamelsiroop)\b", re.IGNORECASE)
    for chunk, store_name in text_chunks:
        matches = pattern.findall(chunk)
        for match in matches:
            food_items.append((match, store_name))
    return food_items

def extract_text_from_pdf_with_ocr(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        pix = page.get_pixmap()
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        text += pytesseract.image_to_string(img, lang='nld')  # Use 'nld' for Dutch
    return text

if __name__ == '__main__':
    chat_history = []

    # Example PDF paths
    pdf_paths = [
        "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf",
        "/content/Folder_ Aldi.pdf",
        "/content/Albert Heijn - Bonus week 20 2024.pdf",
        "/content/Folder_Dirk.pdf",
        "/content/Folder_Jumbo.pdf"
        # Add more PDF paths if needed
    ]

    # Extract text from multiple PDFs
    combined_pdf_text = extract_text_from_multiple_pdfs(pdf_paths)

    # Split the extracted PDF text and include store names
    pdf_text_chunks = []
    for text, store_name in combined_pdf_text:
        pdf_text_chunks.extend(split_text(text, store_name))

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        response = process_chat(agentExecutor, user_input, chat_history, pdf_text_chunks)

        print("Assistant: ", response)

    # Print all extracted food items
    print("Extracted Food Items: ", response)

### Newest code

# Ensure to install the required packages first:
# pip install pymupdf langchain-openai langchain-core langchain-agents langchain-community pillow pytesseract

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter
import re
import pytesseract
from PIL import Image

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history, pdf_text_chunks):
    all_food_items = []
    for chunk in pdf_text_chunks:
        food_items = extract_food_items([chunk])
        all_food_items.extend(food_items)

    response_text = "\n".join(all_food_items)

    chat_history.append(HumanMessage(content=user_input))
    chat_history.append(AIMessage(content=response_text))

    return response_text

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def extract_food_items(text_chunks):
    food_items = []
    pattern = re.compile(r"\b(?:voedsel|drank|product|item|eten|drinken|artikel|appel|krieltjes|asperges|lente-ui|rabarber|haakse slijper|volkorenbollen|koekrepen|choco muesli|kaas|eieren|shoarma|vegan shoarma|kaasmix|smeerkaaspuntjes|pancakes|wraps|burrata|koffiebonen|koffiedrank|gehakt|steaks|forelfilets|makreelfilet|kipfiletstukjes|wokgarnalen|zalmfilets|hamburgers|chipolataworstjes|garnalenspies|partysauzen|tortillachips|pommes frites|notenmix|batterijen|handzeep|chicken wings|rucola|perziken|nectarines|watermeloen|kipkerrie|tomaten|roerbakgroenten|pepersteaks|kabeljauwburgers|kiploempia's|muffins|yoghurt|currysnack|rendang|loaded fries|falafel|pizza|bladerdeeghapjes|stoofvlees|gehaktballen|scampi fritti|knoflookboter|knoflookbrood|kimchi|atjar|bakmix|ijs|breekbrood|borrelbroodjes|karamelsiroop)\b", re.IGNORECASE)  # Adjust the pattern as needed
    for chunk in text_chunks:
        matches = pattern.findall(chunk)
        food_items.extend(matches)
    return food_items

def extract_text_from_pdf_with_ocr(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        pix = page.get_pixmap()
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        text += pytesseract.image_to_string(img, lang='nld')  # Use 'nld' for Dutch
    return text

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Albert Heijn - Bonus week 20 2024.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Use OCR if necessary
    # pdf_text = extract_text_from_pdf_with_ocr(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        response = process_chat(agentExecutor, user_input, chat_history, pdf_text_chunks)

        print("Assistant: ", response)

    # Print all extracted food items
    print("Extracted Food Items: ", response)

#!pip install beautifulsoup4 requests

### Highest potential for a working pdf extractor. Will test out if a 'for loop' or a 'while loop' can help in making this code pdf extraction more accurate
## V2

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter
import re  # For regex operations

# Model initialization
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

# Prompt template setup
prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

# Initialize search tool
search = TavilySearchResults()
tools = [search]

# Create agent
agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

# Initialize agent executor
agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text("text")  # Ensure plain text extraction
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def clean_text(text):
    # Remove unwanted characters and normalize text
    text = text.replace('\n', ' ')
    text = re.sub(r'\s+', ' ', text)
    return text

def find_food_items(text_chunk):
    # Define a regex pattern for Dutch food items based on your list
    pattern = re.compile(r'\b(Evelina appels|Mini-krieltjes|Geschilde witte asperges|Lente-ui|Rabarber|Volkorenbollen|Koekrepen|Choco muesli|Stuk bio kaas|Scharreleieren|Shoarma|Vegan shoarma|Geraspte kaasmix|Smeerkaaspuntjes|Pancakes Amerikaanse stijl|Wraps|Burrata|Koffiebonen|Koffiedrank|Extra mager gehakt|BBQ-steaks|Gerookte forelfilets|Gerookte makreelfilet|Kipfiletstukjes|Wokgarnalen|Gemarineerde zalmfilets|Hamburgers|Chipolataworstjes|Gemarineerde garnalenspies|Partysauzen|Tortillachips|Pommes frites|Notenmix|Navulverpakking handzeep|Chicken wings|Rucola-slamelange|Perziken|Nectarines|Watermeloen|Verspakket kipkerrie|Tomaten|Roerbakgroenten|Pepersteaks|Kabeljauwburgers|Verse kiploempia\'s|Smarties-muffins|Volle yoghurt|Currysnack|Rendang|Loaded fries|Spicy falafel|BBQ chicken pizza|Bladerdeeghapjes|Stoofvlees|Ketjapgehaktballen|Scampi fritti|Knoflookboter-garnalen|Knoflookbrood|Verse kimchi of atjar|Bakmix regenboogcake|Zuurstok-ijs|Breekbrood|Mini borrelbroodjes|Karamelsiroop)\b', re.UNICODE)
    return pattern.findall(text_chunk)

if __name__ == '__main__':
    chat_history = []

    # Example PDF paths
    pdf_paths = [
        "/content/Folder_Jumbo.pdf"
    ]

    # Extract text from each PDF
    pdf_text = ""
    for pdf_path in pdf_paths:
        pdf_text += extract_text_from_pdf(pdf_path) + "\n"

    pdf_text = clean_text(pdf_text)  # Clean the extracted text

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # List to store all unique food items
    food_items = set()

    # Extract items from each chunk
    for chunk in pdf_text_chunks:
        items = find_food_items(chunk)
        food_items.update(items)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include food items in the user input
        user_input_with_food_items = f"{user_input}\n\nExtracted Food Items:\n{', '.join(food_items)}"

        response = process_chat(agentExecutor, user_input_with_food_items, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

### Code Cell #1

##V2

import fitz  # PyMuPDF
import re  # For regex operations

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text("text")  # Ensure plain text extraction
    return text

def split_text(raw_text):
    from langchain.text_splitter import CharacterTextSplitter
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def clean_text(text):
    # Remove unwanted characters and normalize text
    text = text.replace('\n', ' ')
    text = re.sub(r'\s+', ' ', text)
    return text

def find_food_items(text_chunk):
    # Define a regex pattern for Dutch food items based on your list
    pattern = re.compile(r'\b(Evelina appels|Mini-krieltjes|Geschilde witte asperges|Lente-ui|Rabarber|Volkorenbollen|Koekrepen|Choco muesli|Stuk bio kaas|Scharreleieren|Shoarma|Vegan shoarma|Geraspte kaasmix|Smeerkaaspuntjes|Pancakes Amerikaanse stijl|Wraps|Burrata|Koffiebonen|Koffiedrank|Extra mager gehakt|BBQ-steaks|Gerookte forelfilets|Gerookte makreelfilet|Kipfiletstukjes|Wokgarnalen|Gemarineerde zalmfilets|Hamburgers|Chipolataworstjes|Gemarineerde garnalenspies|Partysauzen|Tortillachips|Pommes frites|Notenmix|Navulverpakking handzeep|Chicken wings|Rucola-slamelange|Perziken|Nectarines|Watermeloen|Verspakket kipkerrie|Tomaten|Roerbakgroenten|Pepersteaks|Kabeljauwburgers|Verse kiploempia\'s|Smarties-muffins|Volle yoghurt|Currysnack|Rendang|Loaded fries|Spicy falafel|BBQ chicken pizza|Bladerdeeghapjes|Stoofvlees|Ketjapgehaktballen|Scampi fritti|Knoflookboter-garnalen|Knoflookbrood|Verse kimchi of atjar|Bakmix regenboogcake|Zuurstok-ijs|Breekbrood|Mini borrelbroodjes|Karamelsiroop)\b', re.UNICODE)
    return pattern.findall(text_chunk)

# Extract and process PDF to get food items
def extract_food_items_from_pdf(pdf_path):
    pdf_text = extract_text_from_pdf(pdf_path)
    pdf_text = clean_text(pdf_text)
    pdf_text_chunks = split_text(pdf_text)
    food_items = set()
    for chunk in pdf_text_chunks:
        items = find_food_items(chunk)
        food_items.update(items)
    return food_items

# Example PDF path
pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
food_items = extract_food_items_from_pdf(pdf_path)

# Display extracted food items
food_items_list = list(food_items)
print("Extracted Food Items:", food_items_list)

### Code Cell #2

### V2.1 (w/Beautiful Soup webscrapper

import requests
from bs4 import BeautifulSoup

def search_recipes(ingredient_list):
    base_url = "https://www.allrecipes.com/search/results/?wt="
    query = "%20".join(ingredient_list)
    search_url = base_url + query
    response = requests.get(search_url)
    soup = BeautifulSoup(response.text, 'html.parser')

    recipes = []
    # Debug: Print the entire page's HTML to check structure
    print(soup.prettify())

    # Updated selectors based on the current website structure
    for card in soup.find_all('article', class_='fixed-recipe-card'):
        title_tag = card.find('span', class_='fixed-recipe-card__title-link')
        link_tag = card.find('a', class_='fixed-recipe-card__title-link')
        desc_tag = card.find('div', class_='fixed-recipe-card__description')

        if title_tag and link_tag and desc_tag:
            title = title_tag.get_text(strip=True)
            link = link_tag['href']
            description = desc_tag.get_text(strip=True)
            recipes.append({
                "title": title,
                "link": link,
                "description": description
            })
        if len(recipes) >= 7:
            break

    return recipes

# Load the extracted food items from the previous cell
food_items = food_items_list

# Fetch recipes
recipes = search_recipes(food_items)

# Format the recipes for output
formatted_recipes = ""
for recipe in recipes:
    formatted_recipes += f"**{recipe['title']}**\n"
    formatted_recipes += f"- **Ingredients**: {', '.join(food_items)}\n"
    formatted_recipes += f"- **Preparation Time**: N/A\n"
    formatted_recipes += f"- **Cooking Time**: N/A\n"
    formatted_recipes += f"- **Description**: {recipe['description']}\n"
    formatted_recipes += f"- [Recipe Link]({recipe['link']})\n\n"

print("Assistant: ", formatted_recipes)

### Code Cell #1

##V1.3

import fitz  # PyMuPDF
import re  # For regex operations

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text("text")  # Ensure plain text extraction
    return text

def split_text(raw_text):
    from langchain.text_splitter import CharacterTextSplitter
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def clean_text(text):
    # Remove unwanted characters and normalize text
    text = text.replace('\n', ' ')
    text = re.sub(r'\s+', ' ', text)
    return text

def find_food_items(text_chunk):
    # Define a regex pattern for Dutch food items based on your list
    pattern = re.compile(r'\b(Evelina appels|Mini-krieltjes|Geschilde witte asperges|Lente-ui|Rabarber|Volkorenbollen|Koekrepen|Choco muesli|Stuk bio kaas|Scharreleieren|Shoarma|Vegan shoarma|Geraspte kaasmix|Smeerkaaspuntjes|Pancakes Amerikaanse stijl|Wraps|Burrata|Koffiebonen|Koffiedrank|Extra mager gehakt|BBQ-steaks|Gerookte forelfilets|Gerookte makreelfilet|Kipfiletstukjes|Wokgarnalen|Gemarineerde zalmfilets|Hamburgers|Chipolataworstjes|Gemarineerde garnalenspies|Partysauzen|Tortillachips|Pommes frites|Notenmix|Navulverpakking handzeep|Chicken wings|Rucola-slamelange|Perziken|Nectarines|Watermeloen|Verspakket kipkerrie|Tomaten|Roerbakgroenten|Pepersteaks|Kabeljauwburgers|Verse kiploempia\'s|Smarties-muffins|Volle yoghurt|Currysnack|Rendang|Loaded fries|Spicy falafel|BBQ chicken pizza|Bladerdeeghapjes|Stoofvlees|Ketjapgehaktballen|Scampi fritti|Knoflookboter-garnalen|Knoflookbrood|Verse kimchi of atjar|Bakmix regenboogcake|Zuurstok-ijs|Breekbrood|Mini borrelbroodjes|Karamelsiroop)\b', re.UNICODE)
    return pattern.findall(text_chunk)

# Extract and process PDF to get food items
def extract_food_items_from_pdf(pdf_path):
    pdf_text = extract_text_from_pdf(pdf_path)
    pdf_text = clean_text(pdf_text)
    pdf_text_chunks = split_text(pdf_text)
    food_items = set()
    for chunk in pdf_text_chunks:
        items = find_food_items(chunk)
        food_items.update(items)
    return food_items

# Example PDF path
pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
food_items = extract_food_items_from_pdf(pdf_path)

# Display extracted food items
food_items_list = list(food_items)
print("Extracted Food Items:", food_items_list)

### Code Cell #2

### V1.3 (w/Beautiful Soup webscrapper)

import requests
from bs4 import BeautifulSoup
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage

# Function to perform web search and get valid recipe links from predefined websites
def search_recipes(ingredient_list):
    websites = [
        "allrecipes.com",
        "foodnetwork.com",
        "epicurious.com",
        "bbcgoodfood.com",
        "jamieoliver.com"
    ]
    recipes = []
    for site in websites:
        query = f"site:{site} recipes with " + " ".join(ingredient_list)
        search_url = f"https://www.google.com/search?q={query}"
        response = requests.get(search_url)
        soup = BeautifulSoup(response.text, 'html.parser')
        for link in soup.find_all('a', href=True):
            href = link['href']
            if 'url?q=' in href:
                recipe_url = href.split('url?q=')[1].split('&')[0]
                if site in recipe_url:
                    recipes.append(recipe_url)
            if len(recipes) >= 7:
                break
        if len(recipes) >= 7:
            break
    return recipes

# Initialize agent for recipe finding
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a sophisticated recipe finder. Your goal is to help users find recipes on the internet based on the pdf that is uploaded in this code. You will provide working links to these recipes. Here’s how you will proceed:

1. **Ingredients**: You will receive a list of ingredients from the pdf uploaded in this code.
2. **Search**: You will search for recipes that use these ingredients as the main components.
3. **Filter**: Ensure the recipes are relevant, easy to follow, and have working links.
4. **Output**: Provide a list of recipe titles with short descriptions, list of ingredients, preparation and cooking times, and working links to the full recipes.

### Instructions:
- Only consider the ingredients provided by the user, unless dietary restrictions are mentioned.
- Prioritize recipes as follows: main dishes > lunch dishes > breakfast dishes > sides > snacks.
- Gather recipes from the most relevant cooking websites first. Ensure the links are:
  1. Working.
  2. Exact to the recipe name you provide.
- Include preparation and cooking times, recipe names, and list of ingredients.
- Provide 7 recipe suggestions per query.
- If you need more information, ask the user specific questions.

### Example Interaction:

**User**: I have chicken, rice, and broccoli. What can I make?

**Response**:
1. **Chicken and Rice Casserole**
   - **Ingredients**: Chicken, rice, broccoli, cream of chicken soup, cheese, onion, garlic.
   - **Preparation Time**: 15 minutes
   - **Cooking Time**: 45 minutes
   - **Description**: A delicious and easy-to-make casserole that combines chicken, rice, and broccoli in a creamy sauce.
   - [Recipe Link](https://example.com/chicken-rice-casserole)

2. **Broccoli Chicken Stir-Fry**
   - **Ingredients**: Chicken, broccoli, rice, soy sauce, garlic, ginger, sesame oil.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 15 minutes
   - **Description**: A quick stir-fry with chicken, broccoli, and rice in a savory sauce.
   - [Recipe Link](https://example.com/broccoli-chicken-stir-fry)

3. **Chicken Broccoli Rice Bowl**
   - **Ingredients**: Chicken, rice, broccoli, soy sauce, sesame seeds, green onions.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 20 minutes
   - **Description**: A healthy bowl featuring chicken, rice, and broccoli with a touch of soy sauce.
   - [Recipe Link](https://example.com/chicken-broccoli-rice-bowl)

4. **Chicken Broccoli Bake**
   - **Ingredients**: Chicken, broccoli, cheese, breadcrumbs, milk, butter, flour.
   - **Preparation Time**: 20 minutes
   - **Cooking Time**: 30 minutes
   - **Description**: A creamy bake that blends chicken and broccoli with a cheesy topping.
   - [Recipe Link](https://example.com/chicken-broccoli-bake)

5. **Chicken Fried Rice**
   - **Ingredients**: Chicken, rice, broccoli, soy sauce, eggs, carrots, peas.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 20 minutes
   - **Description**: A classic fried rice dish with chicken, broccoli, and mixed vegetables.
   - [Recipe Link](https://example.com/chicken-fried-rice)

6. **Chicken and Broccoli Alfredo**
   - **Ingredients**: Chicken, broccoli, fettuccine, Alfredo sauce, Parmesan cheese, garlic.
   - **Preparation Time**: 15 minutes
   - **Cooking Time**: 25 minutes
   - **Description**: A rich Alfredo pasta with chicken and broccoli.
   - [Recipe Link](https://example.com/chicken-broccoli-alfredo)

7. **Broccoli Chicken Quesadillas**
   - **Ingredients**: Chicken, broccoli, tortillas, cheese, onion, bell pepper.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 10 minutes
   - **Description**: Tasty quesadillas filled with chicken, broccoli, and melted cheese.
   - [Recipe Link](https://example.com/broccoli-chicken-quesadillas)

Feel free to ask more questions or refine your ingredients list.
"""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

# Load the extracted food items from the previous cell
food_items = food_items_list

# Interact with the user
chat_history = []
while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
        break

    # Include food items in the user input
    user_input_with_food_items = f"{user_input}\n\nExtracted Food Items:\n{', '.join(food_items)}"
    response = process_chat(agentExecutor, user_input_with_food_items, chat_history)

    # Get valid recipe links
    recipe_links = search_recipes(food_items)
    response += "\n\nValid Recipe Links:\n" + "\n".join(recipe_links)

    # Add the most recent input and response to the chat_history
    chat_history.append(HumanMessage(content=user_input))
    chat_history.append(AIMessage(content=response))

    print("Assistant: ", response)

#### I merge these codes in chatgpt: 1) ###THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1.1 SUPERPROMPT + VERIFIED PDF DATA V3.5 ###
### AND 2)#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT

### V2 | Doesn't work

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter
import re  # For regex operations

# Model initialization
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

# Prompt template setup for food item extraction
prompt_food_extraction = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

# Prompt template setup for recipe finding
prompt_recipe_finder = ChatPromptTemplate.from_messages([
    ("system", """You are a sophisticated recipe finder. Your goal is to help users find recipes on the internet based on the pdf that is uploaded in this code. You will provide working links to these recipes. Here’s how you will proceed:

1. **Ingredients**: You will receive a list of ingredients from the pdf uploaded in this code.
2. **Search**: You will search for recipes that use these ingredients as the main components.
3. **Filter**: Ensure the recipes are relevant, easy to follow, and have working links.
4. **Output**: Provide a list of recipe titles with short descriptions, list of ingredients, preparation and cooking times, and working links to the full recipes.

### Instructions:
- Only consider the ingredients provided by the user, unless dietary restrictions are mentioned.
- Prioritize recipes as follows: main dishes > lunch dishes > breakfast dishes > sides > snacks.
- Gather recipes from the most relevant cooking websites first. Ensure the links are:
  1. Working.
  2. Exact to the recipe name you provide.
- Include preparation and cooking times, recipe names, and list of ingredients.
- Provide 7 recipe suggestions per query.
- If you need more information, ask the user specific questions.

### Example Interaction:

**User**: I have chicken, rice, and broccoli. What can I make?

**Response**:
1. **Chicken and Rice Casserole**
   - **Ingredients**: Chicken, rice, broccoli, cream of chicken soup, cheese, onion, garlic.
   - **Preparation Time**: 15 minutes
   - **Cooking Time**: 45 minutes
   - **Description**: A delicious and easy-to-make casserole that combines chicken, rice, and broccoli in a creamy sauce.
   - [Recipe Link](https://example.com/chicken-rice-casserole)

2. **Broccoli Chicken Stir-Fry**
   - **Ingredients**: Chicken, broccoli, rice, soy sauce, garlic, ginger, sesame oil.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 15 minutes
   - **Description**: A quick stir-fry with chicken, broccoli, and rice in a savory sauce.
   - [Recipe Link](https://example.com/broccoli-chicken-stir-fry)

3. **Chicken Broccoli Rice Bowl**
   - **Ingredients**: Chicken, rice, broccoli, soy sauce, sesame seeds, green onions.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 20 minutes
   - **Description**: A healthy bowl featuring chicken, rice, and broccoli with a touch of soy sauce.
   - [Recipe Link](https://example.com/chicken-broccoli-rice-bowl)

4. **Chicken Broccoli Bake**
   - **Ingredients**: Chicken, broccoli, cheese, breadcrumbs, milk, butter, flour.
   - **Preparation Time**: 20 minutes
   - **Cooking Time**: 30 minutes
   - **Description**: A creamy bake that blends chicken and broccoli with a cheesy topping.
   - [Recipe Link](https://example.com/chicken-broccoli-bake)

5. **Chicken Fried Rice**
   - **Ingredients**: Chicken, rice, broccoli, soy sauce, eggs, carrots, peas.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 20 minutes
   - **Description**: A classic fried rice dish with chicken, broccoli, and mixed vegetables.
   - [Recipe Link](https://example.com/chicken-fried-rice)

6. **Chicken and Broccoli Alfredo**
   - **Ingredients**: Chicken, broccoli, fettuccine, Alfredo sauce, Parmesan cheese, garlic.
   - **Preparation Time**: 15 minutes
   - **Cooking Time**: 25 minutes
   - **Description**: A rich Alfredo pasta with chicken and broccoli.
   - [Recipe Link](https://example.com/chicken-broccoli-alfredo)

7. **Broccoli Chicken Quesadillas**
   - **Ingredients**: Chicken, broccoli, tortillas, cheese, onion, bell pepper.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 10 minutes
   - **Description**: Tasty quesadillas filled with chicken, broccoli, and melted cheese.
   - [Recipe Link](https://example.com/broccoli-chicken-quesadillas)

Feel free to ask more questions or refine your ingredients list.
"""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

# Initialize search tool
search = TavilySearchResults()
tools = [search]

# Create agents
agent_food_extraction = create_openai_functions_agent(
    llm=model,
    prompt=prompt_food_extraction,
    tools=tools
)

agent_recipe_finder = create_openai_functions_agent(
    llm=model,
    prompt=prompt_recipe_finder,
    tools=tools
)

# Initialize agent executors
agent_executor_food_extraction = AgentExecutor(
    agent=agent_food_extraction,
    tools=tools
)

agent_executor_recipe_finder = AgentExecutor(
    agent=agent_recipe_finder,
    tools=tools
)

def process_chat(agent_executor, user_input, chat_history):
    response = agent_executor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text("text")  # Ensure plain text extraction
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def clean_text(text):
    # Remove unwanted characters and normalize text
    text = text.replace('\n', ' ')
    text = re.sub(r'\s+', ' ', text)
    return text

def find_food_items(text_chunk):
    # Define a regex pattern for Dutch food items based on your list
    pattern = re.compile(r'\b(Evelina appels|Mini-krieltjes|Geschilde witte asperges|Lente-ui|Rabarber|Volkorenbollen|Koekrepen|Choco muesli|Stuk bio kaas|Scharreleieren|Shoarma|Vegan shoarma|Geraspte kaasmix|Smeerkaaspuntjes|Pancakes Amerikaanse stijl|Wraps|Burrata|Koffiebonen|Koffiedrank|Extra mager gehakt|BBQ-steaks|Gerookte forelfilets|Gerookte makreelfilet|Kipfiletstukjes|Wokgarnalen|Gemarineerde zalmfilets|Hamburgers|Chipolataworstjes|Gemarineerde garnalenspies|Partysauzen|Tortillachips|Pommes frites|Notenmix|Navulverpakking handzeep|Chicken wings|Rucola-slamelange|Perziken|Nectarines|Watermeloen|Verspakket kipkerrie|Tomaten|Roerbakgroenten|Pepersteaks|Kabeljauwburgers|Verse kiploempia\'s|Smarties-muffins|Volle yoghurt|Currysnack|Rendang|Loaded fries|Spicy falafel|BBQ chicken pizza|Bladerdeeghapjes|Stoofvlees|Ketjapgehaktballen|Scampi fritti|Knoflookboter-garnalen|Knoflookbrood|Verse kimchi of atjar|Bakmix regenboogcake|Zuurstok-ijs|Breekbrood|Mini borrelbroodjes|Karamelsiroop)\b', re.UNICODE)
    return pattern.findall(text_chunk)

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)
    pdf_text = clean_text(pdf_text)  # Clean the extracted text

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # List to store all unique food items
    food_items = set()

    # Extract items from each chunk
    for chunk in pdf_text_chunks:
        items = find_food_items(chunk)
        food_items.update(items)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Step 1: Extract food items from the PDF and include them in the user input
        user_input_with_food_items = f"{user_input}\n\nExtracted Food Items:\n{', '.join(food_items)}"
        response_food_extraction = process_chat(agent_executor_food_extraction, user_input_with_food_items, chat_history)

        # Step 2: Use the extracted food items to find recipes
        response_recipe_finder = process_chat(agent_executor_recipe_finder, response_food_extraction, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response_recipe_finder))

        print("Assistant: ", response_recipe_finder)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V9 (prompt > regex)

import fitz  # PyMuPDF
import re
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter

# Define the list of Dutch food items for filtering
dutch_food_items = [
    "Evelina appels", "Mini-krieltjes", "Geschilde witte asperges", "Lente-ui", "Rabarber",
    "Volkorenbollen", "Koekrepen", "Choco muesli", "Stuk bio kaas", "Scharreleieren",
    "Shoarma", "Vegan shoarma", "Geraspte kaasmix", "Smeerkaaspuntjes", "Pancakes Amerikaanse stijl",
    "Wraps", "Burrata", "Koffiebonen", "Koffiedrank", "Extra mager gehakt", "BBQ-steaks",
    "Gerookte forelfilets", "Gerookte makreelfilet", "Kipfiletstukjes", "Wokgarnalen", "Gemarineerde zalmfilets",
    "Hamburgers", "Chipolataworstjes", "Gemarineerde garnalenspies", "Partysauzen", "Tortillachips",
    "Pommes frites", "Notenmix", "Chicken wings", "Rucola-slamelange", "Perziken", "nectarines",
    "Watermeloen", "Verspakket kipkerrie", "tomaten", "Roerbakgroenten", "Pepersteaks",
    "Kabeljauwburgers", "Verse kiploempia's", "volle yoghurt", "Currysnack",
    "Rendang", "Loaded fries", "Spicy falafel", "BBQ chicken pizza", "Bladerdeeghapjes",
    "Stoofvlees", "Ketjapgehaktballen", "Scampi fritti", "Knoflookboter-garnalen", "Knoflookbrood",
    "Verse kimchi of atjar", "Bakmix regenboogcake", "Zuurstok-ijs", "Breekbrood", "Mini borrelbroodjes",
    "Karamelsiroop"
]

# Initialize the model and agent
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", "You will act as an expert in PDF text extraction and Python programming to help me extract product names from grocery brochures. I have a custom-made chatbot coded with the fitz library from PyMuPDF to read these PDFs. The brochures contain a lot of randomly placed text and images. My goal is to extract all the product names from the PDF and create a CSV list that includes only edible and drinkable products, specified with Dutch keywords. Currently, I'm facing two main issues: 1) only parts of the PDF are added to the list, and not the entire PDF, and 2) non-food items are being added to the list. Here’s an example of how I communicate: 'Hi, I'm working on a chatbot project using Python and the fitz library from PyMuPDF to read PDFs. My goal is to extract product names from grocery brochures and make a list of only edible and drinkable products. However, I'm encountering issues with incomplete extraction and inclusion of non-food items. Can you help me solve these issues?' 1. Provide a solution to effectively extract all product names from the entire PDF and ensure that only edible and drinkable items are included in the CSV list. The solution should include steps or code snippets using the fitz library and be capable of recognizing Dutch keywords related to grocery food items. The CSV should have the following columns: 'Store Name, Start Date, End Date, Product Name, Product Weight Number, Product Weight Unit, Product Before Price, Product After Price' and the date format should be YYYY-MM-DD. Additionally, the code should include error handling for cases where the PDF text extraction fails or produces incomplete results. 2. Suggest any improvements to optimize the extraction process and enhance the accuracy of identifying edible and drinkable products."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def filter_food_items(text):
    lines = text.split("\n")
    filtered_items = []
    for line in lines:
        for item in dutch_food_items:
            if re.search(r'\b' + re.escape(item) + r'\b', line, re.IGNORECASE):
                filtered_items.append(line)
                break
    return filtered_items

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # Filter the food items from the PDF text
    filtered_food_items = filter_food_items(pdf_text)

    # Output the list of filtered food items
    print("Filtered Food Items:", filtered_food_items)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include PDF text chunks in the user input
        user_input_with_pdf = f"{user_input}\n\nPDF Content:\n{''.join(pdf_text_chunks)}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V8 (prompt > regex)

import fitz  # PyMuPDF
import csv
import re
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter

# Define the list of Dutch food items for filtering
dutch_food_items = [
    "Evelina appels", "Mini-krieltjes", "Geschilde witte asperges", "Lente-ui", "Rabarber",
    "Haakse slijper", "Volkorenbollen", "Koekrepen", "Choco muesli", "Stuk bio kaas", "Scharreleieren",
    "Shoarma", "Vegan shoarma", "Geraspte kaasmix", "Smeerkaaspuntjes", "Pancakes Amerikaanse stijl",
    "Wraps", "Burrata", "Koffiebonen", "Koffiedrank", "Extra mager gehakt", "BBQ-steaks",
    "Gerookte forelfilets", "Gerookte makreelfilet", "Kipfiletstukjes", "Wokgarnalen", "Gemarineerde zalmfilets",
    "Hamburgers", "Chipolataworstjes", "Gemarineerde garnalenspies", "Partysauzen", "Tortillachips",
    "Pommes frites", "Notenmix", "Batterijen", "Navulverpakking handzeep", "Chicken wings", "Rucola-slamelange",
    "Perziken", "nectarines", "Watermeloen", "Verspakket kipkerrie", "tomaten", "Roerbakgroenten", "Pepersteaks",
    "Kabeljauwburgers", "Verse kiploempia's", "Smarties-muffins", "volle yoghurt", "Currysnack",
    "Rendang", "Loaded fries", "Spicy falafel", "BBQ chicken pizza", "Bladerdeeghapjes",
    "Stoofvlees", "Ketjapgehaktballen", "Scampi fritti", "Knoflookboter-garnalen", "Knoflookbrood",
    "Verse kimchi of atjar", "Bakmix regenboogcake", "Zuurstok-ijs", "Breekbrood", "Mini borrelbroodjes",
    "Karamelsiroop"
]

# Initialize the model and agent
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", "You will act as an expert in PDF text extraction and Python programming to help me extract product names from grocery brochures. I have a custom-made chatbot coded with the fitz library from PyMuPDF to read these PDFs. The brochures contain a lot of randomly placed text and images. My goal is to extract all the product names from the PDF and create a CSV list that includes only edible and drinkable products, specified with Dutch keywords. Currently, I'm facing two main issues: 1) only parts of the PDF are added to the list, and not the entire PDF, and 2) non-food items are being added to the list. Here’s an example of how I communicate: 'Hi, I'm working on a chatbot project using Python and the fitz library from PyMuPDF to read PDFs. My goal is to extract product names from grocery brochures and make a list of only edible and drinkable products. However, I'm encountering issues with incomplete extraction and inclusion of non-food items. Can you help me solve these issues?' 1. Provide a solution to effectively extract all product names from the entire PDF and ensure that only edible and drinkable items are included in the CSV list. The solution should include steps or code snippets using the fitz library and be capable of recognizing Dutch keywords related to grocery food items. The CSV should have the following columns: 'Store Name, Start Date, End Date, Product Name, Product Weight Number, Product Weight Unit, Product Before Price, Product After Price' and the date format should be YYYY-MM-DD. Additionally, the code should include error handling for cases where the PDF text extraction fails or produces incomplete results. 2. Suggest any improvements to optimize the extraction process and enhance the accuracy of identifying edible and drinkable products."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def filter_food_items(text):
    lines = text.split("\n")
    filtered_items = []
    for line in lines:
        for item in dutch_food_items:
            if re.search(r'\b' + re.escape(item) + r'\b', line, re.IGNORECASE):
                filtered_items.append(line)
                break
    return filtered_items

def extract_prices(text):
    price_pattern = re.compile(r'(\d+[\.,]?\d*)')
    prices = price_pattern.findall(text)
    return prices if prices else ["N/A", "N/A"]

def create_csv(food_items, output_path="output.csv"):
    with open(output_path, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Store Name", "Start Date", "End Date", "Product Name", "Product Weight Number", "Product Weight Unit", "Product Before Price", "Product After Price"])
        for item in food_items:
            prices = extract_prices(item)
            writer.writerow(["Lidl", "2024-05-13", "2024-05-20", item, "N/A", "N/A", prices[0], prices[1]])

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # Filter the food items from the PDF text
    filtered_food_items = filter_food_items(pdf_text)

    # Create CSV from the filtered food items
    create_csv(filtered_food_items)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include PDF text chunks in the user input
        user_input_with_pdf = f"{user_input}\n\nPDF Content:\n{''.join(pdf_text_chunks)}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V7 (prompt > regex)


import fitz  # PyMuPDF
import csv
import re
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter

# Define the list of Dutch food items for filtering
dutch_food_items = [
    "Evelina appels", "Mini-krieltjes", "Geschilde witte asperges", "Lente-ui", "Rabarber",
    "Volkorenbollen", "Koekrepen", "Choco muesli", "Stuk bio kaas", "Scharreleieren",
    "Shoarma", "Vegan shoarma", "Geraspte kaasmix", "Smeerkaaspuntjes", "Pancakes Amerikaanse stijl",
    "Wraps", "Burrata", "Koffiebonen", "Koffiedrank", "Extra mager gehakt", "BBQ-steaks",
    "Gerookte forelfilets", "Gerookte makreelfilet", "Kipfiletstukjes", "Wokgarnalen", "Gemarineerde zalmfilets",
    "Hamburgers", "Chipolataworstjes", "Gemarineerde garnalenspies", "Partysauzen", "Tortillachips",
    "Pommes frites", "Notenmix", "Chicken wings", "Rucola-slamelange", "Perziken", "nectarines",
    "Watermeloen", "Verspakket kipkerrie", "tomaten", "Roerbakgroenten", "Pepersteaks",
    "Kabeljauwburgers", "Verse kiploempia's", "Smarties-muffins", "volle yoghurt", "Currysnack",
    "Rendang", "Loaded fries", "Spicy falafel", "BBQ chicken pizza", "Bladerdeeghapjes",
    "Stoofvlees", "Ketjapgehaktballen", "Scampi fritti", "Knoflookboter-garnalen", "Knoflookbrood",
    "Verse kimchi of atjar", "Bakmix regenboogcake", "Zuurstok-ijs", "Breekbrood", "Mini borrelbroodjes",
    "Karamelsiroop"
]

# Initialize the model and agent
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", "You will act as an expert in PDF text extraction and Python programming to help me extract product names from grocery brochures. I have a custom-made chatbot coded with the fitz library from PyMuPDF to read these PDFs. The brochures contain a lot of randomly placed text and images. My goal is to extract all the product names from the PDF and create a CSV list that includes only edible and drinkable products, specified with Dutch keywords. Currently, I'm facing two main issues: 1) only parts of the PDF are added to the list, and not the entire PDF, and 2) non-food items are being added to the list. Here’s an example of how I communicate: 'Hi, I'm working on a chatbot project using Python and the fitz library from PyMuPDF to read PDFs. My goal is to extract product names from grocery brochures and make a list of only edible and drinkable products. However, I'm encountering issues with incomplete extraction and inclusion of non-food items. Can you help me solve these issues?' 1. Provide a solution to effectively extract all product names from the entire PDF and ensure that only edible and drinkable items are included in the CSV list. The solution should include steps or code snippets using the fitz library and be capable of recognizing Dutch keywords related to grocery food items. The CSV should have the following columns: 'Store Name, Start Date, End Date, Product Name, Product Weight Number, Product Weight Unit, Product Before Price, Product After Price' and the date format should be YYYY-MM-DD. Additionally, the code should include error handling for cases where the PDF text extraction fails or produces incomplete results. 2. Suggest any improvements to optimize the extraction process and enhance the accuracy of identifying edible and drinkable products."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def filter_food_items(text):
    lines = text.split("\n")
    filtered_items = []
    for line in lines:
        for item in dutch_food_items:
            if item.lower() in line.lower():
                filtered_items.append(line)
                break
    return filtered_items

def extract_prices(text):
    price_pattern = re.compile(r'(\d+[\.,]?\d*)')
    prices = price_pattern.findall(text)
    return prices if prices else ["N/A", "N/A"]

def create_csv(food_items, output_path="output.csv"):
    with open(output_path, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Store Name", "Start Date", "End Date", "Product Name", "Product Weight Number", "Product Weight Unit", "Product Before Price", "Product After Price"])
        for item in food_items:
            prices = extract_prices(item)
            writer.writerow(["Lidl", "2024-05-13", "2024-05-20", item, "N/A", "N/A", prices[0], prices[1]])

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # Filter the food items from the PDF text
    filtered_food_items = filter_food_items(pdf_text)

    # Create CSV from the filtered food items
    create_csv(filtered_food_items)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include PDF text chunks in the user input
        user_input_with_pdf = f"{user_input}\n\nPDF Content:\n{''.join(pdf_text_chunks)}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V6 (prompt > regex)

import fitz  # PyMuPDF
import csv
import re
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter

# Define the list of Dutch food items for filtering
dutch_food_items = [
    "Evelina appels", "Mini-krieltjes", "Geschilde witte asperges", "Lente-ui", "Rabarber",
    "Volkorenbollen", "Koekrepen", "Choco muesli", "Stuk bio kaas", "Scharreleieren",
    "Shoarma", "Vegan shoarma", "Geraspte kaasmix", "Smeerkaaspuntjes", "Pancakes Amerikaanse stijl",
    "Wraps", "Burrata", "Koffiebonen", "Koffiedrank", "Extra mager gehakt", "BBQ-steaks",
    "Gerookte forelfilets", "Gerookte makreelfilet", "Kipfiletstukjes", "Wokgarnalen", "Gemarineerde zalmfilets",
    "Hamburgers", "Chipolataworstjes", "Gemarineerde garnalenspies", "Partysauzen", "Tortillachips",
    "Pommes frites", "Notenmix", "Chicken wings", "Rucola-slamelange", "Perziken", "nectarines",
    "Watermeloen", "Verspakket kipkerrie", "tomaten", "Roerbakgroenten", "Pepersteaks",
    "Kabeljauwburgers", "Verse kiploempia's", "Smarties-muffins", "volle yoghurt", "Currysnack",
    "Rendang", "Loaded fries", "Spicy falafel", "BBQ chicken pizza", "Bladerdeeghapjes",
    "Stoofvlees", "Ketjapgehaktballen", "Scampi fritti", "Knoflookboter-garnalen", "Knoflookbrood",
    "Verse kimchi of atjar", "Bakmix regenboogcake", "Zuurstok-ijs", "Breekbrood", "Mini borrelbroodjes",
    "Karamelsiroop"
]

# Initialize the model and agent
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def filter_food_items(text):
    lines = text.split("\n")
    filtered_items = []
    for line in lines:
        for item in dutch_food_items:
            if item.lower() in line.lower():
                filtered_items.append(line)
                break
    return filtered_items

def extract_prices(text):
    price_pattern = re.compile(r'(\d+[\.,]?\d*)')
    prices = price_pattern.findall(text)
    return prices if prices else ["N/A", "N/A"]

def create_csv(food_items, output_path="output.csv"):
    with open(output_path, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Store Name", "Start Date", "End Date", "Product Name", "Product Weight Number", "Product Weight Unit", "Product Before Price", "Product After Price"])
        for item in food_items:
            prices = extract_prices(item)
            writer.writerow(["Lidl", "2024-05-13", "2024-05-20", item, "N/A", "N/A", prices[0], prices[1]])

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # Filter the food items from the PDF text
    filtered_food_items = filter_food_items(pdf_text)

    # Create CSV from the filtered food items
    create_csv(filtered_food_items)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include PDF text chunks in the user input
        user_input_with_pdf = f"{user_input}\n\nPDF Content:\n{''.join(pdf_text_chunks)}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V5 (prompt > regex)

## Prompt: from the uploaded pdf, extract all the necessary product names



import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are an assistant that processes grocery brochures to list out all food items with high accuracy."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def create_sequential_prompt(step, data):
    if step == 1:
        return f"""
        **Step 1:** List all product names from the PDF content below.
        Once you have completed this step, state "Step 1 completed: [list of product names]".

        PDF Content:
        {data}
        """
    elif step == 2:
        return f"""
        **Step 2:** Cross-check the listed product names with the PDF content, adding any missing items.
        Repeat this step until the list includes 95-99% of all items in the PDF.
        Once you have completed this step, state "Step 2 completed: [updated list of product names]".

        List from Step 1: {data}
        """
    elif step == 3:
        return f"""
        **Step 3:** Remove all non-food items from the list.
        Once you have completed this step, state "Step 3 completed: [filtered list of food items]".

        List from Step 2: {data}
        """
    elif step == 4:
        return f"""
        **Step 4:** Remove any duplicate or very similar items from the list.
        Once you have completed this step, state "Step 4 completed: [deduplicated list of food items]".

        List from Step 3: {data}
        """
    elif step == 5:
        return f"""
        **Step 5:** Simplify the product names by removing adjectives and keeping only the core product name (e.g., 'dutch strawberries' becomes 'strawberries'; 'alaskan salmon' becomes 'salmon').
        Once you have completed this step, state "Step 5 completed: [simplified list of food items]".

        List from Step 4: {data}
        """
    elif step == 6:
        return f"""
        **Step 6:** Convert the product names to English without altering the structure/format.
        Once you have completed this step, state "Step 6 completed: [final list of food items in English]".

        List from Step 5: {data}
        """

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    step = 1
    data = ''.join(pdf_text_chunks)

    while step <= 6:
        if step == 1:
            prompt_text = create_sequential_prompt(step, data)
        else:
            user_input = input("You: ")
            if user_input.lower() == 'exit':
                break
            prompt_text = create_sequential_prompt(step, data)

        response = process_chat(agentExecutor, prompt_text, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=prompt_text))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

        # Extract the list from the response
        data = response.split("completed: ")[-1].strip("[]").replace("'", "").split(", ")

        step += 1

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V4

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter
import re  # For regex operations

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def find_food_items(text_chunk):
    # Define a regex pattern for Dutch food items
    pattern = re.compile(r'\b[\wèëïäöüÉÈËÏÄÖÜ-]+\s[\wèëïäöüÉÈËÏÄÖÜ-]+\b', re.UNICODE)
    return pattern.findall(text_chunk)

def filter_food_items(items):
    # Keywords to identify food items
    food_keywords = ["appels", "kip", "groenten", "vlees", "yoghurt", "kaas", "brood", "fruit", "saus", "koekjes", "vis", "snoep", "salade", "pasta"]
    filtered_items = [item for item in items if any(keyword in item.lower() for keyword in food_keywords)]
    return filtered_items

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # List to store all unique food items
    food_items = set()

    # Keep looping until no new items are found
    while True:
        initial_count = len(food_items)

        for chunk in pdf_text_chunks:
            items = find_food_items(chunk)
            filtered_items = filter_food_items(items)
            food_items.update(filtered_items)

        # Break the loop if no new items were added
        if len(food_items) == initial_count:
            break

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include food items in the user input
        user_input_with_food_items = f"{user_input}\n\nExtracted Food Items:\n{', '.join(food_items)}"

        response = process_chat(agentExecutor, user_input_with_food_items, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

"""##Most recent code vvvvvvvvvv"""

###THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1.1 SUPERPROMPT + VERIFIED PDF DATA V3.5 ###

##To save time, I stopped adding the previous version. It took up too much space.
#Atm it seemed like a decent idea. Let see if future Josh agrees.

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter
import re  # For regex operations

# Model initialization
model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

# Prompt template setup
prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

# Initialize search tool
search = TavilySearchResults()
tools = [search]

# Create agent
agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

# Initialize agent executor
agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text("text")  # Ensure plain text extraction
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def clean_text(text):
    # Remove unwanted characters and normalize text
    text = text.replace('\n', ' ')
    text = re.sub(r'\s+', ' ', text)
    return text

def find_food_items(text_chunk):
    # Define a regex pattern for Dutch food items based on your list
    pattern = re.compile(r'\b(Evelina appels|Mini-krieltjes|Geschilde witte asperges|Lente-ui|Rabarber|Volkorenbollen|Koekrepen|Choco muesli|Stuk bio kaas|Scharreleieren|Shoarma|Vegan shoarma|Geraspte kaasmix|Smeerkaaspuntjes|Pancakes Amerikaanse stijl|Wraps|Burrata|Koffiebonen|Koffiedrank|Extra mager gehakt|BBQ-steaks|Gerookte forelfilets|Gerookte makreelfilet|Kipfiletstukjes|Wokgarnalen|Gemarineerde zalmfilets|Hamburgers|Chipolataworstjes|Gemarineerde garnalenspies|Partysauzen|Tortillachips|Pommes frites|Notenmix|Navulverpakking handzeep|Chicken wings|Rucola-slamelange|Perziken|Nectarines|Watermeloen|Verspakket kipkerrie|Tomaten|Roerbakgroenten|Pepersteaks|Kabeljauwburgers|Verse kiploempia\'s|Smarties-muffins|Volle yoghurt|Currysnack|Rendang|Loaded fries|Spicy falafel|BBQ chicken pizza|Bladerdeeghapjes|Stoofvlees|Ketjapgehaktballen|Scampi fritti|Knoflookboter-garnalen|Knoflookbrood|Verse kimchi of atjar|Bakmix regenboogcake|Zuurstok-ijs|Breekbrood|Mini borrelbroodjes|Karamelsiroop)\b', re.UNICODE)
    return pattern.findall(text_chunk)

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)
    pdf_text = clean_text(pdf_text)  # Clean the extracted text

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # List to store all unique food items
    food_items = set()

    # Extract items from each chunk
    for chunk in pdf_text_chunks:
        items = find_food_items(chunk)
        food_items.update(items)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include food items in the user input
        user_input_with_food_items = f"{user_input}\n\nExtracted Food Items:\n{', '.join(food_items)}"

        response = process_chat(agentExecutor, user_input_with_food_items, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V3


import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter
import re  # For regex operations

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def find_food_items(text_chunk):
    # Define a regex pattern for Dutch food items
    pattern = re.compile(r'\b[\wéèëïäöüÉÈËÏÄÖÜ-]+\s[\wéèëïäöüÉÈËÏÄÖÜ-]+\b', re.UNICODE)
    return pattern.findall(text_chunk)

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    # List to store all unique food items
    food_items = set()

    # Keep looping until no new items are found
    while True:
        initial_count = len(food_items)

        for chunk in pdf_text_chunks:
            items = find_food_items(chunk)
            food_items.update(items)

        # Break the loop if no new items were added
        if len(food_items) == initial_count:
            break

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include food items in the user input
        user_input_with_food_items = f"{user_input}\n\nExtracted Food Items:\n{', '.join(food_items)}"

        response = process_chat(agentExecutor, user_input_with_food_items, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V2


import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter
import re
from collections import Counter

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def extract_items(text):
    # Basic extraction of words
    words = re.findall(r'\b[A-Za-z]+\b', text)
    # Filter out very short words (e.g., single characters) and frequent common words
    filtered_words = [word for word in words if len(word) > 1]
    # Frequency analysis to filter out very common words
    word_freq = Counter(filtered_words)
    common_words = set(word for word, count in word_freq.items() if count > 50)  # Adjust the threshold as needed
    final_words = [word for word in filtered_words if word not in common_words]
    return set(final_words)

def get_all_items_from_pdf(pdf_path):
    pdf_text = extract_text_from_pdf(pdf_path)
    pdf_text_chunks = split_text(pdf_text)

    all_items = set()
    for chunk in pdf_text_chunks:
        items = extract_items(chunk)
        all_items.update(items)

    return all_items

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    all_items = get_all_items_from_pdf(pdf_path)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include the list of food items in the user input
        user_input_with_pdf = f"{user_input}\n\nFood Items List:\n{', '.join(sorted(all_items))}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Extract any new items mentioned in the response
        new_items = extract_items(response)
        all_items.update(new_items)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT + VERIFIED PDF DATA V1


import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter
import re

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

def extract_items(text):
    # Example regex to extract food items, adjust as necessary
    items = re.findall(r'\b[A-Za-z]+\b', text)
    return set(items)  # Using a set to avoid duplicates

def get_all_items_from_pdf(pdf_path):
    pdf_text = extract_text_from_pdf(pdf_path)
    pdf_text_chunks = split_text(pdf_text)

    all_items = set()
    for chunk in pdf_text_chunks:
        items = extract_items(chunk)
        all_items.update(items)

    return all_items

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    all_items = get_all_items_from_pdf(pdf_path)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include the list of food items in the user input
        user_input_with_pdf = f"{user_input}\n\nFood Items List:\n{', '.join(sorted(all_items))}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Extract any new items mentioned in the response
        new_items = extract_items(response)
        all_items.update(new_items)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF + THE V1 SUPERPROMPT

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a sophisticated recipe finder. Your goal is to help users find recipes on the internet based on the pdf that is uploaded in this code. You will provide working links to these recipes. Here’s how you will proceed:

1. **Ingredients**: You will receive a list of ingredients from the pdf uploaded in this code.
2. **Search**: You will search for recipes that use these ingredients as the main components.
3. **Filter**: Ensure the recipes are relevant, easy to follow, and have working links.
4. **Output**: Provide a list of recipe titles with short descriptions, list of ingredients, preparation and cooking times, and working links to the full recipes.

### Instructions:
- Only consider the ingredients provided by the user, unless dietary restrictions are mentioned.
- Prioritize recipes as follows: main dishes > lunch dishes > breakfast dishes > sides > snacks.
- Gather recipes from the most relevant cooking websites first. Ensure the links are:
  1. Working.
  2. Exact to the recipe name you provide.
- Include preparation and cooking times, recipe names, and list of ingredients.
- Provide 7 recipe suggestions per query.
- If you need more information, ask the user specific questions.

### Example Interaction:

**User**: I have chicken, rice, and broccoli. What can I make?

**Response**:
1. **Chicken and Rice Casserole**
   - **Ingredients**: Chicken, rice, broccoli, cream of chicken soup, cheese, onion, garlic.
   - **Preparation Time**: 15 minutes
   - **Cooking Time**: 45 minutes
   - **Description**: A delicious and easy-to-make casserole that combines chicken, rice, and broccoli in a creamy sauce.
   - [Recipe Link](https://example.com/chicken-rice-casserole)

2. **Broccoli Chicken Stir-Fry**
   - **Ingredients**: Chicken, broccoli, rice, soy sauce, garlic, ginger, sesame oil.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 15 minutes
   - **Description**: A quick stir-fry with chicken, broccoli, and rice in a savory sauce.
   - [Recipe Link](https://example.com/broccoli-chicken-stir-fry)

3. **Chicken Broccoli Rice Bowl**
   - **Ingredients**: Chicken, rice, broccoli, soy sauce, sesame seeds, green onions.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 20 minutes
   - **Description**: A healthy bowl featuring chicken, rice, and broccoli with a touch of soy sauce.
   - [Recipe Link](https://example.com/chicken-broccoli-rice-bowl)

4. **Chicken Broccoli Bake**
   - **Ingredients**: Chicken, broccoli, cheese, breadcrumbs, milk, butter, flour.
   - **Preparation Time**: 20 minutes
   - **Cooking Time**: 30 minutes
   - **Description**: A creamy bake that blends chicken and broccoli with a cheesy topping.
   - [Recipe Link](https://example.com/chicken-broccoli-bake)

5. **Chicken Fried Rice**
   - **Ingredients**: Chicken, rice, broccoli, soy sauce, eggs, carrots, peas.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 20 minutes
   - **Description**: A classic fried rice dish with chicken, broccoli, and mixed vegetables.
   - [Recipe Link](https://example.com/chicken-fried-rice)

6. **Chicken and Broccoli Alfredo**
   - **Ingredients**: Chicken, broccoli, fettuccine, Alfredo sauce, Parmesan cheese, garlic.
   - **Preparation Time**: 15 minutes
   - **Cooking Time**: 25 minutes
   - **Description**: A rich Alfredo pasta with chicken and broccoli.
   - [Recipe Link](https://example.com/chicken-broccoli-alfredo)

7. **Broccoli Chicken Quesadillas**
   - **Ingredients**: Chicken, broccoli, tortillas, cheese, onion, bell pepper.
   - **Preparation Time**: 10 minutes
   - **Cooking Time**: 10 minutes
   - **Description**: Tasty quesadillas filled with chicken, broccoli, and melted cheese.
   - [Recipe Link](https://example.com/broccoli-chicken-quesadillas)

Feel free to ask more questions or refine your ingredients list.
"""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include PDF text chunks in the user input
        user_input_with_pdf = f"{user_input}\n\nPDF Content:\n{''.join(pdf_text_chunks)}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER + THE TOKENIZATION OF THE PDF

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage
from langchain.text_splitter import CharacterTextSplitter  # Correct import for CharacterTextSplitter

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

def split_text(raw_text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=800,
        chunk_overlap=200,
        length_function=len,
    )
    return text_splitter.split_text(raw_text)

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    # Split the extracted PDF text
    pdf_text_chunks = split_text(pdf_text)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include PDF text chunks in the user input
        user_input_with_pdf = f"{user_input}\n\nPDF Content:\n{''.join(pdf_text_chunks)}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE WITH THE CHATBOT AND THE PDF READER

import fitz  # PyMuPDF
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage

model = ChatOpenAI(
    model='gpt-3.5-turbo-0125',
    temperature=0.2
)

prompt = ChatPromptTemplate.from_messages([
    ("system", ""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
    llm=model,
    prompt=prompt,
    tools=tools
)

agentExecutor = AgentExecutor(
    agent=agent,
    tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
    response = agentExecutor.invoke({
        "input": user_input,
        "chat_history": chat_history
    })
    return response["output"]

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text += page.get_text()
    return text

if __name__ == '__main__':
    chat_history = []

    # Example PDF path
    pdf_path = "/content/Folder-Week-20-Landelijk-13-05-20-05-04.pdf"
    pdf_text = extract_text_from_pdf(pdf_path)

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break

        # Include PDF text in the user input
        user_input_with_pdf = f"{user_input}\n\nPDF Content:\n{pdf_text}"

        response = process_chat(agentExecutor, user_input_with_pdf, chat_history)

        # Add the most recent input and response to the chat_history
        chat_history.append(HumanMessage(content=user_input))
        chat_history.append(AIMessage(content=response))

        print("Assistant: ", response)

#THIS IS THE CODE FOR THE CHATBOT



from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage,AIMessage


model = ChatOpenAI(
  model='gpt-3.5-turbo-0125',
  temperature=0.2
)

prompt = ChatPromptTemplate.from_messages ([
  ("system", "You are a friendly chef named Gordan Rhamsey with 20 years of experience in making recipes from ingredients."),
  MessagesPlaceholder(variable_name = "chat_history"),
  ("human", "{input}"),
  MessagesPlaceholder(variable_name = "agent_scratchpad")
])

search = TavilySearchResults()
tools = [search]

agent = create_openai_functions_agent(
  llm=model,
  prompt=prompt,
  tools=tools
)


agentExecutor = AgentExecutor(
  agent=agent,
  tools=tools
)

def process_chat(agentExecutor, user_input, chat_history):
  response = agentExecutor.invoke({
      "input": user_input,
      "chat_history" : chat_history
  })

  return response["output"]

if __name__ == '__main__':
  chat_history =[]

  while True:
    user_input = input("You: ")
    if user_input.lower() == 'exit':
      break

    response = process_chat(agentExecutor, user_input, chat_history)

    #add the most recent input and response to the chat_history
    chat_history.append(HumanMessage(content=user_input))
    chat_history.append(AIMessage(content=response))

    print("Assistant= ", response)